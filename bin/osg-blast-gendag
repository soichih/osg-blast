#!/usr/bin/env node

var version = require("../package").version;
var fs = require('fs');
var which = require('which');
var argv = require('optimist').argv;

var common = require("../common");

console.log("osg-blast-gendag version "+version);

if(!argv.input) {
    console.log("Please specify --input <input directory>");
    process.exit(1);
}

function construct_submit(config, env, query_blocks) {
    var env_str = "";
    for(var key in env) {
        var v = env[key];
        if(v.replace) v = v.replace(/\"/g, "\"\"");
        env_str += key+"="+v+" ";
    }

    var blastpath = which.sync(config.blast);

    //generate blast.condor submit file
    var submit = "";
    submit += "universe=vanilla\n"; 
    submit += "executable="+__dirname+"/../blast.sh\n";
    submit += "notification=never\n";
    submit += "should_transfer_files=YES\n";
    submit += "when_to_transfer_output=ON_EXIT\n";
    submit += "output=log/stdout.$(dbname).q.$(process).$(cluster).txt\n";
    submit += "error=log/stderr.$(dbname).q.$(process).$(cluster).txt\n";
    submit += "transfer_input_files="+blastpath+","+argv.input+"/query.$(process).fa\n";
    submit += "transfer_output_files="+argv.outdir+"\n";
    submit += "environment=\""+env_str+"\"\n";
    submit += "+Description=\"blast job on $(dbname) with query.$(process)\"\n";

    //submit += "periodic_hold=(JobStatus == 1 && (CurrentTime - EnteredCurrentStatus) > 7200) || (JobStatus == 2 && (CurrentTime - EnteredCurrentStatus) > 2400)\n";
    //submit += "periodic_hold_reason=\"test job should timeout in 40 minutes\"\n";

    //automatically release held jobs if it wasn't held by user 
    //https://twiki.grid.iu.edu/bin/view/Documentation/CondorGToGlidein
    //for HoldReasonCode, see http://research.cs.wisc.edu/htcondor/manual/v7.8/11_Appendix_A.html
    submit += "PeriodicRelease = ((CurrentTime - EnteredCurrentStatus) > 60) && (HoldReasonCode =!= 1) && (NumJobStarts <= 10) \n";

    //TODO I don't want DAG to terminate.. how can I do that?
    submit += "periodic_remove = (NumJobStarts > 10) \n"; 

    submit += "Requirements="+config.condor.Requirements+"\n";
    submit += "+PortalUser=\""+config.user+"\"\n";
    submit += "+ProjectName=\""+config.project+"\"\n";
    submit += "request_memory=2000\n"; //2g
    submit += "request_disk=5240000\n"; //5g should be more than enough
    //submit += "log_xml=True\n";

    submit += "\nqueue "+query_blocks+"\n";
    return submit;
}

function construct_submit_merge6(config, query_blocks) {

    var blastpath = which.sync(config.blast);

    var gzfiles = [];
    config.dbinfo.parts.forEach(function(part) {
        gzfiles.push(argv.outdir+'/'+part+'.q.$(process).gz');
    });

    var submit = "";
    submit += "universe=vanilla\n"; 
    submit += "executable="+__dirname+"/../merge6.sh\n";
    submit += "notification=never\n";
    submit += "should_transfer_files=YES\n";
    submit += "when_to_transfer_output=ON_EXIT\n";
    submit += "log=merge6.log\n";
    submit += "output=log/stdout.merge6.q.$(process).$(cluster).txt\n";
    submit += "error=log/stderr.merge6.q.$(process).$(cluster).txt\n";
    submit += "environment=\"outdir="+argv.outdir+" query_block=$(process)\"\n";
    submit += "transfer_input_files="+gzfiles.join(',')+'\n';
    submit += "transfer_output_files="+argv.outdir+"\n";
    submit += "+Description=\"merging blast output (format 6:csv) q.$(process)\"\n";

    //automatically release held jobs if it wasn't held by user 
    //https://twiki.grid.iu.edu/bin/view/Documentation/CondorGToGlidein
    //for HoldReasonCode, see http://research.cs.wisc.edu/htcondor/manual/v7.8/11_Appendix_A.html
    submit += "PeriodicRelease = ((CurrentTime - EnteredCurrentStatus) > 60) && (HoldReasonCode =!= 1) && (NumJobStarts <= 3) \n";
    submit += "periodic_remove = (NumJobStarts > 3) \n"; 

    //Mat's trick to run the job on local job slots
    submit += "requirements = FileSystemDomain =?= \"xd-login.opensciencegrid.org\"\n";
    submit += "+RunOnSubmitNode = True\n";

    //do I need this if I am running it locally?
    submit += "+PortalUser=\""+config.user+"\"\n";
    submit += "+ProjectName=\""+config.project+"\"\n";

    submit += "\nqueue "+query_blocks+"\n";

    return submit;
}

//TODO - does this support the user db? probably not..
function construct_dag(config) {
    var dag = "";    

    //debug (limit to 2 dbs)
    //config.dbinfo.parts = config.dbinfo.parts.splice(1,2);
    
    config.dbinfo.parts.forEach(function(part) {
        dag += "JOB "+part+" blast.condor\n";
        dag += "VARS "+part+" dbname=\""+part+"\"\n";

        //RETRY retires entire db block - even if only 1 query block fails. 
        //we have periodicrelease to retry each query block, and retry via dag just resubmits the entnre db block
        //what we really need is to keep other db block running if 1 node fails, but how?
        dag += "RETRY "+part+" 3\n"; 

        dag += "\n";
    }); 
    return dag;
}

//start out by loading config
common.load_config(function(err, config) {
    if(err) throw err;

    //find number of input files in input directory
    var input_queries = []; 
    fs.readdir(argv.input, function(err, files) {
        if(err) throw err;
        files.forEach(function(file) {
            if(file.indexOf('query.') === 0) input_queries.push(file);
        });
        var query_blocks = input_queries.length;

        //set last minutes condor requirements
        config.condor.Requirements = config.condor.Requirements || "";
        if(config.no_submit) {
            config.no_submit.forEach(function(site) {
                if(config.condor.Requirements != "") config.condor.Requirements += " && ";
                config.condor.Requirements += "(GLIDEIN_ResourceName =!= \""+site+"\")";
            });
        }

        //store submit file
        var env = common.construct_env(config);
        var submit = construct_submit(config, env, query_blocks);
        if(config.debug) {
            console.log("storing blast.condor");
            console.log(submit);
        }
        fs.writeFileSync("blast.condor", submit);

        //store merge6 submit file
        var submit_m6 = construct_submit_merge6(config, query_blocks);
        fs.writeFileSync("blast.merge6.condor", submit_m6);

        //store dag
        var dag = construct_dag(config);
        if(config.debug) {
            console.log("storing blast.dag");
            console.log(dag);
        }
        fs.writeFileSync("blast.dag", dag);
    });
});


